{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T03:45:51.926508Z",
     "start_time": "2025-07-05T03:45:51.917898Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T03:45:52.936265Z",
     "start_time": "2025-07-05T03:45:52.931163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current used model is deepseek-chat\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv(\".env.local\"))\n",
    "\n",
    "model_list = [\"kimi\", \"deepseek\", \"doubao\"]\n",
    "select_model = \"deepseek\"\n",
    "\n",
    "if select_model not in model_list:\n",
    "    raise Exception(\"select model is not valid!\")\n",
    "elif select_model == \"kimi\":\n",
    "    api_key = os.getenv(\"KIMI_API_KEY\")\n",
    "    api_url = os.getenv(\"KIMI_API_URL\")\n",
    "    model_name = os.getenv(\"KIMI_MODEL\")\n",
    "elif select_model == \"deepseek\":\n",
    "    api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    api_url = os.getenv(\"DEEPSEEK_API_URL\")\n",
    "    model_name = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "elif select_model == \"doubao\":\n",
    "    api_key = os.getenv(\"ARK_API_KEY\")\n",
    "    api_url = os.getenv(\"ARK_API_URL\")\n",
    "    model_name = os.getenv(\"ARK_MODEL\")\n",
    "print(f\"current used model is {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试mcp server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T03:46:06.136449Z",
     "start_time": "2025-07-05T03:46:06.041662Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import httpx\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T03:46:06.786374Z",
     "start_time": "2025-07-05T03:46:06.644859Z"
    }
   },
   "outputs": [],
   "source": [
    "async def test_mcp_service():\n",
    "    \"\"\"\n",
    "    测试MCP服务\n",
    "    \"\"\"\n",
    "    # 定义服务URL\n",
    "    SERVICE_URL= \"http://localhost:8000/mcp\"\n",
    "\n",
    "    try:\n",
    "        # 创建流式client\n",
    "        transport = StreamableHttpTransport(url=SERVICE_URL)\n",
    "        # 创建会话\n",
    "        async with Client(transport) as client:\n",
    "            print(f\"成功连接到MCP服务：{SERVICE_URL}\")\n",
    "\n",
    "            # 发送ping请求，进行测试\n",
    "            await client.ping()\n",
    "            print(\"服务心跳检测成功\")\n",
    "\n",
    "            # 获取服务端注册的所有工具\n",
    "            tools = await client.list_tools()\n",
    "            tool_names = [tool.name for tool in tools]\n",
    "            print(f\"可用工具列表：{', '.join(tool_names)}\")\n",
    "\n",
    "            # 调用工具\n",
    "            # 1. 天气工具\n",
    "            weather_results = await client.call_tool(\"weather\", {\"city\": \"北京\"})\n",
    "            weather_data = eval(weather_results.content[0].text)\n",
    "            print(f\"北京天气：温度={weather_data['temp']}, 天气={weather_data['condition']}\")\n",
    "\n",
    "            # 2. 股票工具\n",
    "            stock_results = await client.call_tool(\"stock\", {\"code\": \"600519\"})\n",
    "            stock_data = eval(stock_results.content[0].text)\n",
    "            print(f\"股票查询：名称={stock_data['name']}, 价格={stock_data['price']}\")\n",
    "\n",
    "            # 3.错误测试\n",
    "            try:\n",
    "                error_results = await client.call_tool(\"weather\", {\"city\": \"东京\"})\n",
    "                error_data = eval(error_results.content[0].text)\n",
    "                if error_data and \"error\" in error_data:\n",
    "                    print(f\"错误处理测试：{error_data['error']} - 符合预期\")\n",
    "            except Exception as e:\n",
    "                print(f\"意外错误：{e}\")\n",
    "    except httpx.ConnectError:\n",
    "        print(f\"无法连接到MCP服务{SERVICE_URL}，请检查服务是否启动\")\n",
    "    except Exception as e:\n",
    "        print(f\"测试失败：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MCP服务测试开始\n",
      "==================================================\n",
      "成功连接到MCP服务：http://localhost:8000/mcp\n",
      "服务心跳检测成功\n",
      "可用工具列表：weather, stock\n",
      "北京天气：温度=25, 天气=晴\n",
      "股票查询：名称=贵州茅台, 价格=1825.0\n",
      "错误处理测试：未找到该城市 - 符合预期\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MCP服务测试开始\")\n",
    "print(\"=\"*50)\n",
    "# notobook直接运行\n",
    "await test_mcp_service()\n",
    "# python运行\n",
    "# asyncio.run(test_mcp_service())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用LLM调用MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from fastmcp import Client\n",
    "\n",
    "# 定义服务URL\n",
    "SERVICE_URL= \"http://localhost:8000/mcp\"\n",
    "\n",
    "async def query_mcp_tool(tool_name: str, params: dict):\n",
    "    \"\"\"\n",
    "    调用MCP工具\n",
    "    :param tool_name: 工具名称\n",
    "    :param params: 工具参数\n",
    "    :return: 工具返回结果\n",
    "    \"\"\"\n",
    "\n",
    "    async with Client(SERVICE_URL) as client:\n",
    "        return await client.call_tool(tool_name, params)\n",
    "\n",
    "async def chat_with_tools():\n",
    "    \"\"\"\n",
    "    使用MCP工具进行对话\n",
    "    :return: 对话结果\n",
    "    \"\"\"\n",
    "    # 创建OpenAI客户端\n",
    "    llm_client = AsyncOpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=api_url,\n",
    "    )\n",
    "\n",
    "    # 获取MCP服务的工具列表\n",
    "    async with Client(SERVICE_URL) as mcp_client:\n",
    "        tools = await mcp_client.list_tools()\n",
    "\n",
    "        # 转换为OpenAI工具格式\n",
    "        tool_schemas = []\n",
    "        for tool in tools:\n",
    "            tool_schemas.append({\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description,\n",
    "                        \"parameters\": {\n",
    "                            \"type\": tool.inputSchema.get(\"type\", \"object\"),\n",
    "                            \"properties\": {\n",
    "                                prop_name: prop_def \n",
    "                                for prop_name, prop_def in tool.inputSchema.get(\"properties\", {}).items()\n",
    "                            },\n",
    "                            \"required\": tool.inputSchema.get(\"required\", []),\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # 创建对话\n",
    "    user_query = \"查询北京天气和贵族茅台股份\"\n",
    "\n",
    "    # 调用LLM, 模型自动选择MCP工具\n",
    "    response = await llm_client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "        tools=tool_schemas,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "    # 处理工具调用请求\n",
    "    message = response.choices[0].message\n",
    "    if message.tool_calls:\n",
    "        print(f\"工具调用请求：\\n{message.tool_calls}\")\n",
    "        \n",
    "        # 工具执行\n",
    "        tool_results = []\n",
    "        for call in message.tool_calls:\n",
    "            print(f\"执行工具：{call.function.name}\")\n",
    "            # 调用MCP工具并获取结果\n",
    "            result = await query_mcp_tool(\n",
    "                call.function.name,\n",
    "                eval(call.function.arguments)  # 解析字符串为dict\n",
    "            )\n",
    "            tool_results.append(result)\n",
    "            print(f\"工具调用返回结果：{result}\")\n",
    "        \n",
    "        # 构建工具调用的结果消息\n",
    "        tool_messages = []\n",
    "        for i, call in enumerate(message.tool_calls):\n",
    "            tool_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"name\": call.function.name,\n",
    "                \"content\": tool_results[i].content[0].text\n",
    "            })\n",
    "\n",
    "        # 调用LLM，使用工具调用结果更新对话\n",
    "        final_response = await llm_client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_query},\n",
    "                message,  # 包含工具调用的请求消息\n",
    "                *tool_messages\n",
    "            ]\n",
    "        )\n",
    "        print(f\"最终回复：\\n{final_response.choices[0].message.content}\")\n",
    "    else:\n",
    "        print(f\"直接回复：\\n{response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MCP工具调用测试开始\n",
      "==================================================\n",
      "工具调用请求：\n",
      "[ChatCompletionMessageToolCall(id='call_0_d1fa3e13-49fe-4c07-842f-4254f36d87b2', function=Function(arguments='{\"city\": \"北京\"}', name='weather'), type='function', index=0), ChatCompletionMessageToolCall(id='call_1_f2eabb8f-3e46-4a8b-8272-3ea374e360cc', function=Function(arguments='{\"code\": \"600519\"}', name='stock'), type='function', index=1)]\n",
      "执行工具：weather\n",
      "工具调用返回结果：CallToolResult(content=[TextContent(type='text', text='{\\n  \"temp\": 25,\\n  \"condition\": \"晴\"\\n}', annotations=None, meta=None)], structured_content={'temp': 25, 'condition': '晴'}, data={'temp': 25, 'condition': '晴'}, is_error=False)\n",
      "执行工具：stock\n",
      "工具调用返回结果：CallToolResult(content=[TextContent(type='text', text='{\\n  \"name\": \"贵州茅台\",\\n  \"price\": 1825.0\\n}', annotations=None, meta=None)], structured_content={'name': '贵州茅台', 'price': 1825.0}, data={'name': '贵州茅台', 'price': 1825.0}, is_error=False)\n",
      "最终回复：\n",
      "北京当前天气为晴，气温25℃；贵州茅台（600519）的股票价格为1825.0元。\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MCP工具调用测试开始\")\n",
    "print(\"=\"*50)\n",
    "await chat_with_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
